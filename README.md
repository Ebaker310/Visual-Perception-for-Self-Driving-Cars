Visual Perception for Self Driving Cars
---
This course is part of the Self-Driving Cars Specialization offered by the University of Toronto on Coursera.

Description of course:

This course will introduce you to the main perception tasks in autonomous driving, static and dynamic object detection, and will survey common computer vision methods for robotic perception. By the end of this course, you will be able to:

- work with the pinhole camera model
- perform intrinsic and extrinsic camera calibration
- detect, describe and match image features
- design your own convolutional neural networks

You'll apply these methods to visual odometry, object detection and tracking, and semantic segmentation for drivable surface estimation. These techniques represent the main building blocks of the perception system for self-driving cars. 

<img src="pics/VisualOdometry.PNG" width="330"> <img src="pics/ObjectDetection.PNG" width="350"> <img src="pics/SemanticSeg.PNG" width="300">

For the final project in this course, you will develop algorithms that identify bounding boxes for objects in the scene, and define the boundaries of the drivable surface. You'll work with synthetic and real image data, and evaluate your performance on a realistic dataset. 
